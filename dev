
already table of spa D you will have to make the call and look if there is any changes. If not, then from this point on, you can continue with your flow and you don't need to make any change. If there is a change in this open-up that audit table, let me look at the schema. If there is a record ID or entry in this in this audit, then step three, what you will have to do is you will have to read like you'll have to make one more query to spy DV for that fields that are changed and use it and update the Conv payload that you get and then process it. So this should be done in every tool. This should be done in every tool. Dedicated. Dedicated to tool. Just a second. Let me explain thinking. Can you see my camera? Go. Yeah. Yeah. So what I am suggesting is that whenever you start your flow, you will have Men you start your flow you have these two databases Convore and Spark, right? Yeah. Every Just a pond here. There are not two different databases. There are different tables in same database. So the data is also in Spark database? Yes, same database. Different tables I thought you making a call It's a No, no, no. Different tables in the same database. Okay. My bad. Let's call this as convert table. And there are several spark tables I'm sorry? Several spark tables. Let's call this a convert table. This is the whole thing is inside that's sparked BB. Yes. Okay? Yes. Make a call to this, number one. No matter what, you will make a call to it, and you'll get thatjacent data from it, Jason P.. Okay. You stored it in your in your code, in your MCP tool. Second, make call to this. You'll always have to make call to this and then there will be F condition. If, no entry you find for that particular sp submission IED. Then use this and execute your code. else you will need to make another call. So these two are mandatory, this would be optional. But then the problem here is for that particular submission ID, oh correct, correct if there is change, yeah. And you'll have to make call to the changes table places where the changes are made. Otherwise, more would be your source of truth. Yes. Yeah, yeah. So this flow, this F andL, you'll have to write and there'll be one, two, and three calls to database. Three calls to the database. That will be m in our final payload that we send out will have the conver fetch data and the changed data as well. Both of them concongatinated. Yes, this two has to be concenated and then you give it to your tool and it'll make the decision of fetching the third one or going ahead and presenting with the first one. So this whole thing can be encapsulated and separated from your tools and written once and you can use it in all of the tools. You don't necessarily need to write this for every tool. Okay. But this wait be fixed now. Like you will have something well less utility or helper functions that is this function. Okay. So this would be a separate file. util.t and in that you can write a function that does this. But we need to write just need to write the queries that changes for every tool like for yeah I'm sure that that was the the second idea I I had.. What was the first play? The first one was like, we'll have a centralized centralized tool that only decides which one took uh whether the spark submission had changed or not. So once a centralizer tool decides which to go, so now for every use case, we'll have two kinds of tools. For FL, like for simplified query we have convert tool for FL simplified will have spark tool. Now, now based on the rule engine, it will decide whether to give the input parameters to FL Conver or FL spark. So that is like more complex. This is way easier to implement within a tool encate logic, go and propose it to that I create a separate util function that will first get the payload from Cornwar, get the audit table and get the changes. If there is changes, it will make call to if there is no changes, then it will go ahead and give that payload to your tour. And this would be at the start of your tool. And then you would proceed continue processing the tool, whatever process you are you are making. If there is an entry no table, you will go to those changes, you have to add it to that conwar and con convert payload and then you can use it in the point. So in last in final payload, which we sent to agent, we'll have the con especially noted as conv data and updated data as to concatenated outputs from two different queries, correct then LLM will decide of what the updated data is and based on that it would do the decision making in future. Or will understand that I didn't got you. So in, we are in working ABCD Rosar came. there are four fields that came from convertable, ABCD. Now D is changed. Audit will table will decide and rural best engine will decide and fetch the data. That is from change the table, that is a spark table that is decorum it fetches. Okay, or it will fetch all ABCD. I would suggest that fetch are we have ACD from Conver, then we have D from Spark. Then we' we'll concartinate it by saying these are conver all the data, they are conver data ab and updated data D and then send the whole thing or replace replace the D column from the conv to what this depends on your business use case historical data important. It might be, not might be. So I have to ask about this. So yeah, so ask, most probably you will say no, because this will help you save the token and the context. Yeah, yeah, he said no. Mostly he said, no. conver is not. required. Yeah. So let's say you got from onward, you got A, B, C, and D, B different parts and from ori table, you came to know that BU was changed. So people have to fetch D from sp submission, and you'll have to replace it with the ABC it would be ABC and new D that you will get and then you'll send just that new D to the LNM. Yeah, but the complexity here is based on the audit table, how we can dynamically write that A, ifD changes, then you squee this query if C changes that query, if changes that query, so that will be very complex So that part you will have to write how many sections you have? I think you just have five or six sections, right? now, like for this for this use case, we have six sections, six se. Six sections, right? And your payload of Jason. Yeah. So you will have to in this else, there will be a switch case then. Use a switch case, it is faster than FL, and in switch case, check if it is the changed is A update A, or NSB, update B, or LC update. So it will be all switches. and then you'll have after that switch, you'll have that final pay and return it. so this would change. So let's say in future you have eight different sections or nine different sections, then then you'll have to add more switch. statement. Yeah, yeah, yeah. And But the audit table is just giving the change column change name and and table change name and source of change and time stamp so based on colony change name, we have to decide that which wherever, you know, field lies in within that column. Look out of the six separate parts of Jason? Yeah, yeah. Okay. It's very complex, man. Come on. So, okay, I will, first of all, let him know that this is the. But yeah, this was one of one of the solutions I had in my mind, but yeah, I'll I'll I'll just come up with one diagram and let him know that this is my approach. We'll see then what he He have some solution, but he'tly All the clearly clearly told me, I don't want to tell you discuss you that discussion because it's not my job and you should you should tell me what to do. I'll just give you the requirements. He's crazy. I think he'sing you now. Yeah, he's testing.'s testing. Okay, I will let him know about this Sabro channel. Let's see what he says. Okay, no problem. Okay, thank you. I'm here, so if anything, ping me up, I think your work from home today, right? Yes, yes, yes. Okay. You can ping me up anytime. Sure, sure. Okay. Thank you, man.
